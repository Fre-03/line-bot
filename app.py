import os
import json
import logging
from flask import Flask, request, abort
from linebot.v3 import WebhookHandler
from linebot.v3.messaging import (
    Configuration,
    ApiClient,
    MessagingApi,
    ReplyMessageRequest,
    PushMessageRequest,
    TextMessage,
    QuickReply,
    QuickReplyItem,
    MessageAction
)
from linebot.v3.exceptions import InvalidSignatureError
from linebot.v3.webhooks import MessageEvent, TextMessageContent
from langchain_community.embeddings import HuggingFaceEmbeddings
from langchain_text_splitters import RecursiveCharacterTextSplitter
import psycopg2
from datetime import datetime
import time
import numpy as np
import requests

# é…ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Initialize Flask app
app = Flask(__name__)

# LINE Bot Configuration - Use environment variables
LINE_CHANNEL_ACCESS_TOKEN = os.environ.get('V1sufJIBSKrWjgrLXco7MwlF6nTfUezSNoaWXGp56FYTt9439aLLNutzglbQgkABmwuSQ9M944XUzsWh6ZGMdyXlDQ3VMhVcUfLRB7Q9wcE+HqdK2NA/fr4VOvwKb3xDXAQaaKhaVdHSsizqgeanjgdB04t89/1O/w1cDnyilFU=', '')
LINE_CHANNEL_SECRET = os.environ.get('d2a475a09075ee8842452113564322de', '')
# LINE SDK v3 configuration
configuration = Configuration(access_token=LINE_CHANNEL_ACCESS_TOKEN)
handler = WebhookHandler(LINE_CHANNEL_SECRET)

# PostgreSQL Configuration - Use environment variable
POSTGRES_CONNECTION_STRING = os.environ.get('postgresql://postgres:Sa151120@localhost:5432/chatbot_db', '')

# === AI æœå‹™é…ç½® ===
AI_SERVICE = "rule_engine"

# === é˜²æ­¢é‡è¤‡è™•ç†çš„æ©Ÿåˆ¶ ===
processed_messages = set()
MAX_PROCESSED_MESSAGES = 1000

def is_message_processed(message_id):
    return message_id in processed_messages

def mark_message_processed(message_id):
    if len(processed_messages) >= MAX_PROCESSED_MESSAGES:
        processed_messages.clear()
    processed_messages.add(message_id)

# === RAG çµ„ä»¶ ===
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    length_function=len
)

# === å…è²»æœ¬åœ°åµŒå…¥æ¨¡å‹ ===
try:
    embeddings = HuggingFaceEmbeddings(
        model_name="sentence-transformers/all-mpnet-base-v2",
        model_kwargs={'device': 'cpu'},
        encode_kwargs={'normalize_embeddings': True}
    )
    logger.info("âœ… æœ¬åœ°åµŒå…¥æ¨¡å‹åŠ è¼‰æˆåŠŸï¼")
except Exception as e:
    logger.error(f"âŒ åµŒå…¥æ¨¡å‹åŠ è¼‰å¤±æ•—: {e}")
    embeddings = None

# === è³‡æ–™åº«é€£æ¥å‡½æ•¸ ===
def get_db_connection():
    """ç²å–è³‡æ–™åº«é€£æ¥ï¼ŒåŒ…å«éŒ¯èª¤è™•ç†"""
    try:
        conn = psycopg2.connect(POSTGRES_CONNECTION_STRING)
        return conn
    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
        return None

# === æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ (Include all your existing functions here) ===
# === è³‡æ–™åº«åˆå§‹åŒ–å‡½æ•¸ ===
def init_line_postgresql_database():
    try:
        conn = psycopg2.connect(POSTGRES_CONNECTION_STRING)
        cursor = conn.cursor()
        
        # Enable pgvector extension
        cursor.execute("CREATE EXTENSION IF NOT EXISTS vector;")
        
        # Create LINE users table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS line_users (
                line_user_id TEXT PRIMARY KEY,
                username TEXT,
                role TEXT CHECK(role IN ('student', 'teacher', 'unknown')),
                department TEXT,
                teacher_id TEXT,
                created_at DOUBLE PRECISION DEFAULT EXTRACT(EPOCH FROM NOW()),
                last_active DOUBLE PRECISION DEFAULT EXTRACT(EPOCH FROM NOW())
            );
        ''')
        
        # Create LINE chat history table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS line_chat_history (
                id SERIAL PRIMARY KEY,
                line_user_id TEXT REFERENCES line_users(line_user_id),
                user_message TEXT,
                bot_response TEXT,
                is_teacher_knowledge BOOLEAN DEFAULT FALSE,
                timestamp DOUBLE PRECISION DEFAULT EXTRACT(EPOCH FROM NOW())
            );
        ''')
        
        # Create RAG knowledge base table
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS knowledge_base (
                id SERIAL PRIMARY KEY,
                title TEXT NOT NULL,
                content TEXT NOT NULL,
                content_vector VECTOR(768),
                category TEXT DEFAULT 'general',
                metadata JSONB DEFAULT '{}',
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            );
        ''')
        
        # å°å¸«çŸ¥è­˜åº«è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS teacher_knowledge_base (
                id SERIAL PRIMARY KEY,
                teacher_id TEXT NOT NULL,
                teacher_name TEXT NOT NULL,
                content TEXT NOT NULL,
                content_vector VECTOR(768),
                context TEXT,
                category TEXT DEFAULT 'general',
                source_type TEXT CHECK(source_type IN ('manual', 'auto_captured')),
                captured_at TIMESTAMP DEFAULT NOW(),
                created_at TIMESTAMP DEFAULT NOW()
            );
        ''')
        
        # å°å¸«è³‡æ–™è¡¨
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS teacher_profiles (
                teacher_id TEXT PRIMARY KEY,
                teacher_name TEXT NOT NULL,
                department TEXT,
                contact_info TEXT,
                office_location TEXT,
                expertise TEXT,
                teaching_style TEXT,
                personal_notes TEXT,
                created_at TIMESTAMP DEFAULT NOW(),
                updated_at TIMESTAMP DEFAULT NOW()
            );
        ''')
        
        # å‰µå»ºå‘é‡ç´¢å¼•
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS knowledge_base_vector_idx 
            ON knowledge_base USING ivfflat (content_vector vector_cosine_ops);
        ''')
        
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS teacher_knowledge_vector_idx 
            ON teacher_knowledge_base USING ivfflat (content_vector vector_cosine_ops);
        ''')
        
        logger.info("âœ… è³‡æ–™åº«åˆå§‹åŒ–å®Œæˆï¼")
        cursor.close()
        conn.close()
        
    except Exception as e:
        logger.error(f"âŒ è³‡æ–™åº«åˆå§‹åŒ–éŒ¯èª¤: {e}")

# åˆå§‹åŒ–è³‡æ–™åº«
init_line_postgresql_database()

# === æ ¸å¿ƒåŠŸèƒ½å‡½æ•¸ ===
def create_teacher_profile(teacher_id, teacher_name, department=None, contact_info=None, 
                          office_location=None, expertise=None, teaching_style=None, personal_notes=None):
    try:
        conn = psycopg2.connect(POSTGRES_CONNECTION_STRING)
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO teacher_profiles 
            (teacher_id, teacher_name, department, contact_info, office_location, expertise, teaching_style, personal_notes)
            VALUES (%s, %s, %s, %s, %s, %s, %s, %s)
            ON CONFLICT (teacher_id) 
            DO UPDATE SET 
                teacher_name = EXCLUDED.teacher_name,
                department = EXCLUDED.department,
                contact_info = EXCLUDED.contact_info,
                office_location = EXCLUDED.office_location,
                expertise = EXCLUDED.expertise,
                teaching_style = EXCLUDED.teaching_style,
                personal_notes = EXCLUDED.personal_notes,
                updated_at = NOW()
        ''', (teacher_id, teacher_name, department, contact_info, office_location, expertise, teaching_style, personal_notes))
        
        conn.commit()
        cursor.close()
        conn.close()
        logger.info(f"âœ… å°å¸«è³‡æ–™å·²å„²å­˜: {teacher_name} ({teacher_id})")
        return True
        
    except Exception as e:
        logger.error(f"âŒ å„²å­˜å°å¸«è³‡æ–™éŒ¯èª¤: {e}")
        return False

def add_teacher_knowledge(teacher_id, teacher_name, content, context=None, category="general", source_type="manual"):
    try:
        conn = psycopg2.connect(POSTGRES_CONNECTION_STRING)
        cursor = conn.cursor()
        
        content_vector = embeddings.embed_query(content)
        vector_str = "[" + ",".join(map(str, content_vector)) + "]"
        
        cursor.execute('''
            INSERT INTO teacher_knowledge_base 
            (teacher_id, teacher_name, content, content_vector, context, category, source_type)
            VALUES (%s, %s, %s, %s::vector, %s, %s, %s)
        ''', (teacher_id, teacher_name, content, vector_str, context, category, source_type))
        
        conn.commit()
        cursor.close()
        conn.close()
        logger.info(f"âœ… å·²æ·»åŠ å°å¸«çŸ¥è­˜: {teacher_name}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ·»åŠ å°å¸«çŸ¥è­˜éŒ¯èª¤: {e}")
        return False

def retrieve_teacher_knowledge(query, teacher_id=None, k=3):
    try:
        conn = psycopg2.connect(POSTGRES_CONNECTION_STRING)
        cursor = conn.cursor()
        
        query_vector = embeddings.embed_query(query)
        query_vector_str = "[" + ",".join(map(str, query_vector)) + "]"
        
        if teacher_id:
            sql = '''
                SELECT teacher_name, content, context, category,
                       1 - (content_vector <=> %s::vector) as similarity
                FROM teacher_knowledge_base 
                WHERE teacher_id = %s
                ORDER BY content_vector <=> %s::vector
                LIMIT %s;
            '''
            params = (query_vector_str, teacher_id, query_vector_str, k)
        else:
            sql = '''
                SELECT teacher_name, content, context, category,
                       1 - (content_vector <=> %s::vector) as similarity
                FROM teacher_knowledge_base 
                ORDER BY content_vector <=> %s::vector
                LIMIT %s;
            '''
            params = (query_vector_str, query_vector_str, k)
        
        cursor.execute(sql, params)
        results = cursor.fetchall()
        cursor.close()
        conn.close()
        
        documents = []
        for teacher_name, content, context, category, similarity in results:
            documents.append({
                "teacher_name": teacher_name,
                "content": content,
                "context": context,
                "category": category,
                "similarity": round(similarity, 3)
            })
        
        logger.info(f"ğŸ‘¨â€ğŸ« æª¢ç´¢åˆ° {len(documents)} å€‹å°å¸«çŸ¥è­˜ç‰‡æ®µ")
        return documents
        
    except Exception as e:
        logger.error(f"âŒ æª¢ç´¢å°å¸«çŸ¥è­˜éŒ¯èª¤: {e}")
        return []

def add_to_knowledge_base(title, content, category="general", metadata=None):
    try:
        conn = psycopg2.connect(POSTGRES_CONNECTION_STRING)
        cursor = conn.cursor()
        
        content_vector = embeddings.embed_query(content)
        vector_str = "[" + ",".join(map(str, content_vector)) + "]"
        
        cursor.execute('''
            INSERT INTO knowledge_base (title, content, content_vector, category, metadata)
            VALUES (%s, %s, %s::vector, %s, %s)
        ''', (title, content, vector_str, category, json.dumps(metadata or {})))
        
        conn.commit()
        cursor.close()
        conn.close()
        logger.info(f"âœ… å·²æ·»åŠ çŸ¥è­˜åº«æ–‡ä»¶: {title}")
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ·»åŠ çŸ¥è­˜åº«éŒ¯èª¤: {e}")
        return False

def retrieve_relevant_documents(query, category_filter=None, k=3):
    try:
        conn = psycopg2.connect(POSTGRES_CONNECTION_STRING)
        cursor = conn.cursor()
        
        query_vector = embeddings.embed_query(query)
        query_vector_str = "[" + ",".join(map(str, query_vector)) + "]"
        
        if category_filter:
            sql = '''
                SELECT title, content, 
                       1 - (content_vector <=> %s::vector) as similarity
                FROM knowledge_base 
                WHERE category = %s
                ORDER BY content_vector <=> %s::vector
                LIMIT %s;
            '''
            params = (query_vector_str, category_filter, query_vector_str, k)
        else:
            sql = '''
                SELECT title, content, 
                       1 - (content_vector <=> %s::vector) as similarity
                FROM knowledge_base 
                ORDER BY content_vector <=> %s::vector
                LIMIT %s;
            '''
            params = (query_vector_str, query_vector_str, k)
        
        cursor.execute(sql, params)
        results = cursor.fetchall()
        cursor.close()
        conn.close()
        
        documents = []
        for title, content, similarity in results:
            documents.append({
                "title": title,
                "content": content,
                "similarity": round(similarity, 3)
            })
        
        logger.info(f"ğŸ“š æª¢ç´¢åˆ° {len(documents)} å€‹ç›¸é—œæ–‡ä»¶")
        return documents
        
    except Exception as e:
        logger.error(f"âŒ æª¢ç´¢éŒ¯èª¤: {e}")
        return []

# === åˆå§‹åŒ–ç¯„ä¾‹è³‡æ–™ ===
def initialize_sample_data():
    # çŸ¥è­˜åº«è³‡æ–™
    sample_data = [
        {
            "title": "åœ–æ›¸é¤¨ä½ç½®èˆ‡é–‹æ”¾æ™‚é–“",
            "content": "å­¸æ ¡åœ–æ›¸é¤¨ä½æ–¼è¡Œæ”¿å¤§æ¨“æ—é‚Šçš„ç´…è‰²å»ºç¯‰ç‰©ã€‚é–‹æ”¾æ™‚é–“ï¼šé€±ä¸€è‡³é€±äº” 8:00-22:00ï¼Œé€±å…­æ—¥ 9:00-17:00ã€‚å¾æ ¡é–€å£é€²å…¥å¾Œç›´èµ°ï¼Œçœ‹åˆ°è¡Œæ”¿å¤§æ¨“å¾Œå·¦è½‰ï¼Œåœ–æ›¸é¤¨å°±åœ¨å³æ‰‹é‚Šã€‚",
            "category": "campus_navigation"
        },
        {
            "title": "è«‹å‡æµç¨‹èªªæ˜",
            "content": "å­¸ç”Ÿè«‹å‡æµç¨‹ï¼š1. å‘å°å¸«è«‹å‡ç²å¾—åŒæ„ 2. å¡«å¯«å­¸æ ¡è«‹å‡å–® 3. é€è‡³ç³»è¾¦æ ¸å‡† 4. å°‡æ ¸å‡†å–®äº¤çµ¦èª²ç¨‹åŠ©æ•™ã€‚ç·Šæ€¥æƒ…æ³å¯å…ˆå£é ­è«‹å‡ï¼Œäº‹å¾Œè£œè¾¦æ‰‹çºŒã€‚",
            "category": "student_affairs"
        }
    ]
    
    # å°å¸«è³‡æ–™
    sample_teachers = [
        {
            "teacher_id": "T001",
            "teacher_name": "å¼µè€å¸«",
            "department": "è¨ˆç®—æ©Ÿç§‘å­¸ç³»",
            "contact_info": "åˆ†æ©Ÿ: 1234, Email: chang@school.edu",
            "office_location": "å·¥ç¨‹å¤§æ¨“ 301å®¤",
            "expertise": "äººå·¥æ™ºæ…§, æ©Ÿå™¨å­¸ç¿’, è³‡æ–™åº«ç³»çµ±",
            "teaching_style": "æ³¨é‡å¯¦ä½œï¼Œé¼“å‹µå­¸ç”Ÿæå•",
            "personal_notes": "è¾¦å…¬å®¤æ™‚é–“: é€±äºŒã€å›› 14:00-16:00"
        }
    ]
    
    # å°å¸«çŸ¥è­˜
    sample_knowledge = [
        {
            "teacher_id": "T001",
            "teacher_name": "å¼µè€å¸«",
            "content": "ç¨‹å¼ä½œæ¥­çš„è©•åˆ†æ¨™æº–ä¸»è¦çœ‹ç¨‹å¼é‚è¼¯æ­£ç¢ºæ€§ã€ç¨‹å¼ç¢¼é¢¨æ ¼å’Œè¨»è§£å®Œæ•´æ€§ã€‚é²äº¤ä¸€é€±å…§æ‰£20%ï¼Œè¶…éä¸€é€±ä¸äºˆè¨ˆåˆ†ã€‚",
            "context": "é—œæ–¼ä½œæ¥­è©•åˆ†æ¨™æº–çš„èªªæ˜",
            "category": "grading"
        }
    ]
    
    # æ·»åŠ è³‡æ–™
    for data in sample_data:
        add_to_knowledge_base(data["title"], data["content"], data["category"])
    
    for teacher in sample_teachers:
        create_teacher_profile(**teacher)
    
    for knowledge in sample_knowledge:
        add_teacher_knowledge(**knowledge)
    
    logger.info("âœ… ç¯„ä¾‹è³‡æ–™åˆå§‹åŒ–å®Œæˆ")

initialize_sample_data()

def get_line_user_role(line_user_id):
    try:
        conn = get_db_connection()
        if conn is None:
            return {'role': 'unknown', 'username': None, 'department': None, 'teacher_id': None}
            
        cursor = conn.cursor()
        
        cursor.execute(
            "SELECT role, username, department, teacher_id FROM line_users WHERE line_user_id = %s",
            (line_user_id,)
        )
        result = cursor.fetchone()
        cursor.close()
        conn.close()
        
        if result:
            return {
                'role': result[0],
                'username': result[1],
                'department': result[2],
                'teacher_id': result[3]
            }
        
        return {'role': 'unknown', 'username': None, 'department': None, 'teacher_id': None}
        
    except Exception as e:
        logger.error(f"âŒ ç²å–ç”¨æˆ¶è§’è‰²éŒ¯èª¤: {e}")
        return {'role': 'unknown', 'username': None, 'department': None, 'teacher_id': None}

def update_line_user_role(line_user_id, role, username=None, department=None, teacher_id=None):
    try:
        conn = get_db_connection()
        if conn is None:
            return False
            
        cursor = conn.cursor()
        
        cursor.execute('''
            INSERT INTO line_users (line_user_id, username, role, department, teacher_id, last_active)
            VALUES (%s, %s, %s, %s, %s, EXTRACT(EPOCH FROM NOW()))
            ON CONFLICT (line_user_id) 
            DO UPDATE SET 
                username = EXCLUDED.username,
                role = EXCLUDED.role,
                department = EXCLUDED.department,
                teacher_id = EXCLUDED.teacher_id,
                last_active = EXCLUDED.last_active
        ''', (line_user_id, username, role, department, teacher_id))
        
        conn.commit()
        cursor.close()
        conn.close()
        return True
        
    except Exception as e:
        logger.error(f"âŒ æ›´æ–°ç”¨æˆ¶è§’è‰²éŒ¯èª¤: {e}")
        return False

def generate_simple_response(user_message, user_profile):
    """è¦å‰‡å¼•æ“ - è™•ç†å¸¸è¦‹å•é¡Œ"""
    message_lower = user_message.lower()
    
    if any(word in message_lower for word in ['åœ–æ›¸é¤¨', 'library']):
        return "ğŸ« åœ–æ›¸é¤¨è³‡è¨Šï¼š\nğŸ“ ä½ç½®ï¼šè¡Œæ”¿å¤§æ¨“æ—é‚Šçš„ç´…è‰²å»ºç¯‰ç‰©\nâ° é–‹æ”¾æ™‚é–“ï¼šé€±ä¸€è‡³é€±äº” 8:00-22:00ï¼Œé€±å…­æ—¥ 9:00-17:00"
    
    elif any(word in message_lower for word in ['è«‹å‡', 'è«‹å‡æµç¨‹', 'ç¼ºèª²', 'æ€éº¼è«‹å‡']):
        return "ğŸ“ è«‹å‡æµç¨‹ï¼š\n1. å‘å°å¸«è«‹å‡ç²å¾—åŒæ„\n2. å¡«å¯«å­¸æ ¡è«‹å‡å–®\n3. é€è‡³ç³»è¾¦æ ¸å‡†\n4. å°‡æ ¸å‡†å–®äº¤çµ¦èª²ç¨‹åŠ©æ•™"
    
    elif any(word in message_lower for word in ['å¼µè€å¸«', 't001']):
        return "ğŸ‘¨â€ğŸ« å¼µè€å¸«è³‡è¨Šï¼š\nğŸ« ç³»æ‰€ï¼šè¨ˆç®—æ©Ÿç§‘å­¸ç³»\nğŸ“ è¾¦å…¬å®¤ï¼šå·¥ç¨‹å¤§æ¨“ 301å®¤\nğŸ“ è¯çµ¡ï¼šåˆ†æ©Ÿ 1234"
    
    elif any(word in message_lower for word in ['hi', 'hello', 'ä½ å¥½', 'å—¨']):
        role_text = "åŒå­¸" if user_profile.get('role') == 'student' else "è€å¸«" if user_profile.get('role') == 'teacher' else "æœ‹å‹"
        return f"ğŸ‘‹ ä½ å¥½{role_text}ï¼æˆ‘æ˜¯ Freya å­¸ä¼´ï¼"
    
    return None

def generate_rag_response(user_message, line_user_id, user_profile):
    """RAG å¢å¼·ç‰ˆå›æ‡‰ç”Ÿæˆ"""
    logger.info(f"ğŸ” RAG è™•ç†è¨Šæ¯: {user_message}")
    
    # 1. é¦–å…ˆå˜—è©¦è¦å‰‡å¼•æ“
    simple_response = generate_simple_response(user_message, user_profile)
    if simple_response:
        return simple_response
    
    # 2. æª¢ç´¢ç›¸é—œæ–‡ä»¶
    relevant_docs = []
    teacher_knowledge = []
    
    try:
        relevant_docs = retrieve_relevant_documents(user_message, k=3, similarity_threshold=0.3)
        teacher_knowledge = retrieve_teacher_knowledge(user_message, k=2, similarity_threshold=0.3)
    except Exception as e:
        logger.error(f"âŒ æª¢ç´¢éç¨‹éŒ¯èª¤: {e}")
    
    # 3. æº–å‚™ä¸Šä¸‹æ–‡
    context = ""
    if relevant_docs or teacher_knowledge:
        context += "ğŸ“š ç›¸é—œè³‡è¨Šï¼š\n\n"
        
        if relevant_docs:
            context += "ğŸ« æ ¡åœ’è³‡è¨Šï¼š\n"
            for i, doc in enumerate(relevant_docs, 1):
                context += f"{i}. ã€{doc['title']}ã€‘\n"
                context += f"   {doc['content']}\n\n"
        
        if teacher_knowledge:
            context += "ğŸ‘¨â€ğŸ« å°å¸«èªªæ˜ï¼š\n"
            for i, knowledge in enumerate(teacher_knowledge, 1):
                context += f"{i}. ã€{knowledge['teacher_name']}ã€‘\n"
                context += f"   {knowledge['content']}\n\n"
    
    if context:
        return f"""ğŸ¤– é—œæ–¼ã€Œ{user_message}ã€ï¼Œæˆ‘æ‰¾åˆ°ä»¥ä¸‹è³‡è¨Šï¼š

{context}

å¦‚æœé€™æ²’æœ‰å®Œå…¨è§£ç­”æ‚¨çš„å•é¡Œï¼Œå»ºè­°ç›´æ¥è¯ç¹«ç›¸é—œç³»è¾¦ï¼ğŸ˜Š"""
    else:
        return f"""ğŸ¤– æˆ‘äº†è§£æ‚¨æƒ³è©¢å•ã€Œ{user_message}ã€

ç›®å‰æˆ‘çš„çŸ¥è­˜åº«ä¸­æ²’æœ‰ç›¸é—œçš„è©³ç´°è³‡è¨Šã€‚å»ºè­°æ‚¨ï¼š
â€¢ ç›´æ¥è¯ç¹«ç›¸é—œç³»è¾¦
â€¢ è©¢å•èª²ç¨‹å°å¸«

æˆ‘æœƒæŒçºŒå­¸ç¿’ï¼Œæœªä¾†ç‚ºæ‚¨æä¾›æ›´å¥½çš„æœå‹™ï¼ğŸ“š"""

# === Message Queue System ===
def store_pending_message(line_user_id, user_message, reply_token=None):
    """Store message in database for processing"""
    try:
        conn = get_db_connection()
        if conn is None:
            return False
            
        cursor = conn.cursor()
        
        # Create pending_messages table if not exists
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS pending_messages (
                id SERIAL PRIMARY KEY,
                line_user_id TEXT NOT NULL,
                user_message TEXT NOT NULL,
                reply_token TEXT,
                received_at TIMESTAMP DEFAULT NOW(),
                processed BOOLEAN DEFAULT FALSE
            )
        ''')
        
        cursor.execute('''
            INSERT INTO pending_messages (line_user_id, user_message, reply_token)
            VALUES (%s, %s, %s)
        ''', (line_user_id, user_message, reply_token))
        
        conn.commit()
        cursor.close()
        conn.close()
        logger.info(f"ğŸ“¥ Stored pending message from {line_user_id}")
        return True
    except Exception as e:
        logger.error(f"âŒ Error storing pending message: {e}")
        return False

def send_line_message(user_id, message_text):
    """Send message to LINE user"""
    try:
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.push_message(
                PushMessageRequest(
                    to=user_id,
                    messages=[TextMessage(text=message_text)]
                )
            )
        logger.info(f"âœ… Sent message to {user_id}")
        return True
    except Exception as e:
        logger.error(f"âŒ Failed to send message: {e}")
        return False

def send_line_reply(reply_token, message_text):
    """Send reply using reply token"""
    try:
        with ApiClient(configuration) as api_client:
            line_bot_api = MessagingApi(api_client)
            line_bot_api.reply_message(
                ReplyMessageRequest(
                    reply_token=reply_token,
                    messages=[TextMessage(text=message_text)]
                )
            )
        logger.info(f"âœ… Sent reply to {reply_token}")
        return True
    except Exception as e:
        logger.error(f"âŒ Failed to send reply: {e}")
        return False

# === Webhook Endpoint ===
@app.route("/webhook", methods=['POST'])
def webhook():
    signature = request.headers.get('X-Line-Signature', '')
    body = request.get_data(as_text=True)
    
    if not signature:
        abort(400)
    
    try:
        handler.handle(body, signature)
        return 'OK'
    except InvalidSignatureError:
        abort(400)
    except Exception as e:
        logger.error(f"âŒ Webhook éŒ¯èª¤: {e}")
        abort(500)

@handler.add(MessageEvent, message=TextMessageContent)
def handle_message(event):
    try:
        message_id = event.message.id
        line_user_id = event.source.user_id
        user_message = event.message.text.strip()
        reply_token = event.reply_token
        
        logger.info(f"ğŸ’¬ Received message from {line_user_id}: {user_message}")
        
        # Store message for processing
        store_pending_message(line_user_id, user_message, reply_token)
        
        # Send immediate acknowledgment
        immediate_response = "â³ å·²æ”¶åˆ°æ‚¨çš„è¨Šæ¯ï¼Œæ­£åœ¨è™•ç†ä¸­..."
        send_line_reply(reply_token, immediate_response)
        
    except Exception as e:
        logger.error(f"âŒ Error handling message: {e}")

@app.route("/")
def home():
    return "ğŸš€ LINE Bot is running!"

if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5000))
    app.run(host="0.0.0.0", port=port)